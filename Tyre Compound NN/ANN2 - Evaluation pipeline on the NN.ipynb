{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ede0162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.utils import shuffle\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import models, layers, regularizers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033e3c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df\n",
    "df = pd.read_csv(r'f1dataset2.csv', encoding='utf-8')\n",
    "\n",
    "# shuffle data\n",
    "shuffled_data = df.sample(frac=1, random_state=42)  # Set random_state for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556e40a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, precision_recall_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from tensorflow.keras import models, layers, regularizers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the seed value\n",
    "np.random.seed(42)\n",
    "\n",
    "# Separate test races\n",
    "test_races = shuffled_data['race_id'].unique()[:10]  # 10 test races\n",
    "excluded_races = test_races.tolist()\n",
    "\n",
    "# Exclude test races from the dataset\n",
    "train_data = shuffled_data[~shuffled_data['race_id'].isin(test_races)]\n",
    "test_data = shuffled_data[shuffled_data['race_id'].isin(test_races)]\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "n_folds = 10\n",
    "\n",
    "# Initialize StratifiedKFold with the desired number of folds\n",
    "stratified_kfold = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store evaluation results\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "precision_per_fold = []\n",
    "recall_per_fold = []\n",
    "\n",
    "# Define the model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(210, activation='relu', input_shape=(29,), kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=0.0009218034891406539),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Separate input features (X) and target variable (y) for the train and test sets\n",
    "X_train = train_data[['race_progress', 'remaining_pit_stops', 'location', 'fulfilled_second_compound', 'number_of_available_compounds']]\n",
    "y_train = train_data['relativecompound']\n",
    "\n",
    "X_test = test_data[['race_progress', 'remaining_pit_stops', 'location', 'fulfilled_second_compound', 'number_of_available_compounds']]\n",
    "y_test = test_data['relativecompound']\n",
    "\n",
    "# Separate categorical and numerical features\n",
    "cat_features = ['remaining_pit_stops', 'location', 'fulfilled_second_compound', 'number_of_available_compounds']\n",
    "num_features = ['race_progress']\n",
    "\n",
    "# Perform preprocessing on numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train[num_features] = scaler.fit_transform(X_train[num_features])\n",
    "X_test[num_features] = scaler.transform(X_test[num_features])\n",
    "\n",
    "# Create a ColumnTransformer to apply OneHotEncoder on categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), cat_features)],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Fit the preprocessor on the training data and transform both training and test data\n",
    "X_train_encoded = preprocessor.fit_transform(X_train)\n",
    "X_test_encoded = preprocessor.transform(X_test)  # Add this line to transform the test data\n",
    "\n",
    "# Encode the target variable using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Iterate over the folds\n",
    "for train_index, val_index in stratified_kfold.split(X_train_encoded, y_train_encoded):\n",
    "    # Get the training and validation subsets for the current fold\n",
    "    X_train_fold = X_train_encoded[train_index]\n",
    "    y_train_fold = y_train_encoded[train_index]\n",
    "    X_val_fold = X_train_encoded[val_index]\n",
    "    y_val_fold = y_train_encoded[val_index]\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train_fold, y_train_fold, validation_data=(X_val_fold, y_val_fold), batch_size=32, epochs=10)\n",
    "\n",
    "    # Predict probabilities on the validation set\n",
    "    y_val_pred_prob = model.predict(X_val_fold)\n",
    "\n",
    "    # Convert predicted probabilities to predicted labels\n",
    "    y_val_pred = np.argmax(y_val_pred_prob, axis=1)\n",
    "\n",
    "    # Calculate evaluation metrics for the validation set\n",
    "    val_accuracy = accuracy_score(y_val_fold, y_val_pred)\n",
    "    val_precision = precision_score(y_val_fold, y_val_pred, average='macro', zero_division=0)\n",
    "    val_recall = recall_score(y_val_fold, y_val_pred, average='macro')\n",
    "    val_f1 = f1_score(y_val_fold, y_val_pred, average='macro')\n",
    "\n",
    "    # Calculate precision and recall for the validation set\n",
    "    n_classes = y_val_pred_prob.shape[1]\n",
    "    precision, recall, _ = precision_recall_curve(y_val_fold, y_val_pred_prob[:, 1], pos_label=1)\n",
    "    precision_per_fold.append(precision)\n",
    "    recall_per_fold.append(recall)\n",
    "\n",
    "    # Store evaluation metrics for the validation set\n",
    "    accuracy_scores.append(val_accuracy)\n",
    "    precision_scores.append(val_precision)\n",
    "    recall_scores.append(val_recall)\n",
    "    f1_scores.append(val_f1)\n",
    "\n",
    "# Predict probabilities on the test set\n",
    "y_test_pred_prob = model.predict(X_test_encoded)\n",
    "\n",
    "# Convert predicted probabilities to predicted labels\n",
    "y_test_pred = np.argmax(y_test_pred_prob, axis=1)\n",
    "\n",
    "# Calculate evaluation metrics for the test set\n",
    "test_accuracy = accuracy_score(y_test_encoded, y_test_pred)\n",
    "test_precision = precision_score(y_test_encoded, y_test_pred, average='macro', zero_division=0)\n",
    "test_recall = recall_score(y_test_encoded, y_test_pred, average='macro')\n",
    "test_f1 = f1_score(y_test_encoded, y_test_pred, average='macro')\n",
    "\n",
    "# Store evaluation metrics for the test set\n",
    "accuracy_scores.append(test_accuracy)\n",
    "precision_scores.append(test_precision)\n",
    "recall_scores.append(test_recall)\n",
    "f1_scores.append(test_f1)\n",
    "\n",
    "# Calculate and print the average evaluation metrics for the test set\n",
    "print('Average Test Accuracy:', np.mean(accuracy_scores))\n",
    "print('Average Test Precision:', np.mean(precision_scores))\n",
    "print('Average Test Recall:', np.mean(recall_scores))\n",
    "print('Average Test F1 Score:', np.mean(f1_scores))\n",
    "\n",
    "# Plot the precision-recall curve for each fold\n",
    "plt.figure()\n",
    "for fold in range(n_folds):\n",
    "    plt.plot(recall_per_fold[fold], precision_per_fold[fold], label='Fold {}'.format(fold + 1))\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve for 10 Folds')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
