{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b81261",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "import sklearn\n",
    "from sklearn.metrics import f1_score\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVC\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import History\n",
    "from keras.layers import Dense\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree, export_text\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import decomposition, datasets, linear_model\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, mean_squared_error, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069be242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df\n",
    "df = pd.read_csv(r\"f1dataset2.csv\", encoding='utf-8')\n",
    "\n",
    "# shuffle data\n",
    "df.sample(frac=1, random_state=42)  # Set random_state for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6410dd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encode = LabelEncoder()\n",
    "df['relativecompound'] = label_encode.fit_transform(df['relativecompound']) #hard = 0 , med = 1 , soft = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc7b5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate categorical and numerical features\n",
    "cat_features = ['remaining_pit_stops', 'location', 'fulfilled_second_compound', 'number_of_available_compounds']\n",
    "num_features = ['race_progress']\n",
    "\n",
    "# Splitting the data into input features (X) and pit stop labels (y)\n",
    "x_cat = df[cat_features]\n",
    "x_num = df[num_features]\n",
    "X = pd.concat([x_cat, x_num], axis=1)\n",
    "y = df['relativecompound']\n",
    "\n",
    "# One-hot encoding categorical features\n",
    "encoder = OneHotEncoder()\n",
    "X_encoded = encoder.fit_transform(x_cat).toarray()\n",
    "\n",
    "# Combining encoded categorical features with numerical features\n",
    "X = np.concatenate((X_encoded, x_num), axis=1)\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86377ae9",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cc713f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the SVM classifier\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = svm.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd41166",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_svm = f1_score(y_test, y_pred, average='weighted')\n",
    "print(\"F1 score:\", f1_svm*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a82d88",
   "metadata": {},
   "source": [
    "## DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df477305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the decision tree classifier\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = tree.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631b2190",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_dt = f1_score(y_test, y_pred, average='weighted')\n",
    "print(\"F1 score:\", f1_dt*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666dc9f1",
   "metadata": {},
   "source": [
    "## LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b126f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the logistic regression model with increased max_iter\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = lr.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6908829f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_lr = f1_score(y_test, y_pred, average='weighted')\n",
    "print(\"F1 score:\", f1_lr * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43cdc8e",
   "metadata": {},
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8bbeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit label encoder on y_train and transform y_train and y_test\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Determine the number of classes (unique labels)\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# Define the neural network architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(16, activation='relu', input_dim=X_train_scaled.shape[1]))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))  # Sigmoid activation for binary classification\n",
    "\n",
    "# Compile the model with binary cross-entropy loss\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model using the encoded labels\n",
    "model.fit(X_train_scaled, y_train_encoded, epochs=10, batch_size=32, validation_data=(X_test_scaled, y_test_encoded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e321a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred_prob = model.predict(X_test_scaled)\n",
    "y_pred_labels = np.argmax(y_pred_prob, axis=1)  \n",
    "\n",
    "# Calculate the F1 score\n",
    "f1_nn = f1_score(y_test_encoded, y_pred_labels, average='weighted')\n",
    "print(\"F1 score:\", f1_nn * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
